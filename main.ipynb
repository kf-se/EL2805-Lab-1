{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0) [(0, 0, 0, 0)] [-1.  0.  0.  0.  0.]\n",
      "(0, 0, 0, 0) [(0, 0, 0, 0)] [  -1. -100.    0.    0.    0.]\n",
      "(0, 0, 0, 0) [(0, 0, 0, 0)] [  -1. -100. -100.    0.    0.]\n",
      "(0, 0, 0, 0) [(0, 0, 0, 0)] [  -1. -100. -100. -100.    0.]\n",
      "(0, 0, 0, 0) [(0, 0, 0, 0)] [  -1. -100. -100. -100. -100.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import temp as mz\n",
    "maze = np.array([[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                 [0, 0, 1, 0, 0, 0, 1, 0, 0], \n",
    "                 [0, 0, 1, 0, 0, 0, 1, 1, 0],\n",
    "                 [0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
    "                 [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                 [0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "                 [0, 0, 0, 0, 0, 0, 1, 2, 0]])\n",
    "#mz.draw_maze(maze)\n",
    "env = mz.Maze(maze, minotaur_moves=4)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) What are the states and actions? Given a pair, can I determine the probabilities of the next state? If not, there is a mistake in the formulation.\n",
    "\n",
    "2) Given a state and an action, what are the probabilities of the next states? First try to determine which states are definitely impossible (0 probability). For the remaining ones, try to justify what the probability of each one should be, based on the problem description.\n",
    "\n",
    "3) What are the rewards associated with the states? These should come from the problem description. Does it say that we punish the player for every step? Do we punish him for dying? Do we reward him for reaching the exit? Does it matter how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1. -100. -100. -100. -100.]\n",
      " [   0. -100.    0. -100.    0.]\n",
      " [   0. -100.    0. -100.    0.]\n",
      " ...\n",
      " [   0.    2. -100.    0. -100.]\n",
      " [   0.    2. -100.    0. -100.]\n",
      " [  -1. -100. -100. -100. -100.]]\n"
     ]
    }
   ],
   "source": [
    "print(env.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "policy at end position [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Finite horizon\n",
    "horizon = 20\n",
    "# Solve the MDP problem with dynamic programming \n",
    "V, policy= mz.dynamic_programming(env,horizon);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "actions[self.STAY]       = (0, 0);\n",
    "actions[self.MOVE_LEFT]  = (0,-1);\n",
    "actions[self.MOVE_RIGHT] = (0, 1);\n",
    "actions[self.MOVE_UP]    = (-1,0);\n",
    "actions[self.MOVE_DOWN]  = (1,0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2961, 5)\n",
      "60\n",
      "[   0. -100.    0. -100.    0.]\n",
      "[   0.    0. -100. -100.    0.]\n",
      "[   0. -100.    0.    0.    0.]\n",
      "{0: (0, 0), 1: (0, -1), 2: (0, 1), 3: (-1, 0), 4: (1, 0)}\n"
     ]
    }
   ],
   "source": [
    "list1 = [\"1\", \"2\"]\n",
    "list2 = (1,2)\n",
    "dict1 = {list2:5}\n",
    "print(env.rewards.shape)\n",
    "print(env.map[(0,0,6,6)])\n",
    "print(env.rewards[60,:])\n",
    "print(env.rewards[env.map[0,1,6,6]])\n",
    "print(env.rewards[env.map[1,0,6,6]])\n",
    "print(env.actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898\n",
      "[   0.    2. -100.    0. -100.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(env.map[(6,8,0,0)])#endpos\n",
    "print(env.rewards[2898,:]) \n",
    "a = [-4, 10000, -100, -4, -100]\n",
    "print(np.argmax(a,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the shortest path starting from position A\n",
    "method = 'DynProg';\n",
    "start  = (0, 0, 6, 5);\n",
    "path = env.simulate(start, policy, method);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 6, 5), (0, 0, 5, 5), (0, 0, 5, 5), (0, 0, 5, 5), (0, 0, 5, 4), (0, 0, 4, 4), (0, 0, 4, 4), (0, 0, 4, 5), (0, 0, 4, 5), (0, 0, 4, 5), (0, 0, 4, 4), (0, 0, 3, 4), (0, 0, 3, 4), (0, 0, 2, 4), (0, 0, 2, 3), (0, 0, 1, 3), (0, 0, 1, 4), (0, 0, 0, 4), (0, 0, 0, 5), (0, 0, 0, 6), (0, 0, 0, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mz.animate_solution(maze, path)\n",
    "#mz.draw_maze(maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
